{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:01:55.346932Z",
     "start_time": "2025-05-21T00:01:55.300309Z"
    }
   },
   "cell_type": "code",
   "source": "!git clone https://github.com/jantic/DeOldify.git",
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'DeOldify' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:01:55.538122Z",
     "start_time": "2025-05-21T00:01:55.534340Z"
    }
   },
   "cell_type": "code",
   "source": "cd DeOldify",
   "id": "113120c54e3134f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xndc4\\PycharmProjects\\masters_project\\DeOldify\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:02:00.158271Z",
     "start_time": "2025-05-21T00:01:55.546481Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -r requirements-colab.txt",
   "id": "364c0d21718ad0b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fastai==1.0.60 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements-colab.txt (line 1)) (1.0.60)\n",
      "Requirement already satisfied: tensorboardX>=1.6 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements-colab.txt (line 2)) (2.6.2.2)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements-colab.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: yt-dlp in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements-colab.txt (line 4)) (2024.12.13)\n",
      "Requirement already satisfied: opencv-python>=4.2.0.32 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements-colab.txt (line 5)) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-colab.txt (line 6)) (10.2.0)\n",
      "Requirement already satisfied: tornado in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-colab.txt (line 7)) (6.3.3)\n",
      "Requirement already satisfied: imgaug==0.2.6 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements-colab.txt (line 8)) (0.2.6)\n",
      "Requirement already satisfied: bottleneck in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.3.7)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.8.0)\n",
      "Requirement already satisfied: numexpr in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.8.7)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: nvidia-ml-py3 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (7.352.0)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.1.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.5.1+cu118)\n",
      "Requirement already satisfied: spacy>=2.0.18 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.8.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.20.1+cu118)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imgaug==0.2.6->-r requirements-colab.txt (line 8)) (0.22.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from imgaug==0.2.6->-r requirements-colab.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboardX>=1.6->-r requirements-colab.txt (line 2)) (3.20.3)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from ffmpeg-python->-r requirements-colab.txt (line 3)) (0.18.3)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (2023.4.12)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (8.3.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (68.2.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.4.0,>=8.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.4.0,>=8.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.1.0)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:02:03.551136Z",
     "start_time": "2025-05-21T00:02:00.163330Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
   "id": "aa08004afd4dbe76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (0.20.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\xndc4\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:02:07.169985Z",
     "start_time": "2025-05-21T00:02:03.563115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "id": "4d9e8b7489a04a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:02:07.204210Z",
     "start_time": "2025-05-21T00:02:07.178609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#NOTE:  This must be the first call in order to work properly!\n",
    "from deoldify import device\n",
    "from deoldify.device_id import DeviceId\n",
    "#choices:  CPU, GPU0...GPU7\n",
    "device.set(device=DeviceId.GPU0)"
   ],
   "id": "e4afb37f3bdf05e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DeviceId.GPU0: 0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:02:11.515186Z",
     "start_time": "2025-05-21T00:02:07.215180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fastai.callbacks.tensorboard import *\n",
    "from fastai.vision.gan import *\n",
    "from deoldify.generators import *\n",
    "from deoldify.critics import *\n",
    "from deoldify.dataset import *\n",
    "from deoldify.loss import *\n",
    "from deoldify.save import *\n",
    "from PIL import Image"
   ],
   "id": "f85cb27b8c11e856",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 20 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:02:12.541545Z",
     "start_time": "2025-05-21T00:02:11.520792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deoldify.visualize import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")"
   ],
   "id": "a2136f05f926a1b0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:02:13.383434Z",
     "start_time": "2025-05-21T00:02:12.556085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "path = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n",
    "train_ds = './data/custom_dataset/norm/train/'\n",
    "sample_train = './data/custom_dataset/norm/sample_train/'\n",
    "valid_ds = './data/custom_dataset/norm/val/'\n",
    "test_ds = './data/custom_dataset/norm/test/'\n",
    "train_bandw = './data/custom_dataset/bandw/train/'\n",
    "val_bandw = './data/custom_dataset/bandw/val/'\n",
    "test_bandw = './data/custom_dataset/bandw/test/'\n",
    "\n",
    "os.makedirs(train_ds, exist_ok=True)\n",
    "os.makedirs(sample_train, exist_ok=True)\n",
    "os.makedirs(valid_ds, exist_ok=True)\n",
    "os.makedirs(test_ds, exist_ok=True)\n",
    "os.makedirs(train_bandw, exist_ok=True)\n",
    "os.makedirs(val_bandw, exist_ok=True)\n",
    "os.makedirs(test_bandw, exist_ok=True)"
   ],
   "id": "cee4b076f6476407",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.12).\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:20:34.999175Z",
     "start_time": "2025-05-21T00:17:46.916665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_files = []\n",
    "full_train = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            all_files.append(os.path.join(root, file.lower()))\n",
    "\n",
    "def copy_file(file_path):\n",
    "    if 'val_' in file_path:\n",
    "        shutil.copy(file_path, valid_ds)\n",
    "    elif 'test_' in file_path:\n",
    "        shutil.copy(file_path, test_ds)\n",
    "    else:\n",
    "        shutil.copy(file_path, train_ds)\n",
    "        full_train.append(file_path)\n",
    "\n",
    "# Use a thread pool to parallelize copying\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(copy_file, all_files)\n",
    "    list(tqdm(executor.map(copy_file, all_files), total=len(all_files)))\n"
   ],
   "id": "ec00d420bda1ec88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240000/240000 [02:40<00:00, 1491.88it/s]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:25:55.540524Z",
     "start_time": "2025-05-21T00:25:55.534784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path = Path('./data/custom_dataset')\n",
    "# path = Path('data/imagenet/ILSVRC/Data/CLS-LOC')\n",
    "path_hr = sample_train\n",
    "path_lr = train_bandw\n",
    "pretrained_gen_path = 'ColorizeArtistic_gen'\n",
    "\n",
    "proj_id = 'ArtisticModel'\n",
    "\n",
    "gen_name = proj_id + '_gen'\n",
    "pre_gen_name = gen_name + '_0'\n",
    "crit_name = proj_id + '_crit'\n",
    "\n",
    "name_gen = proj_id + '_image_gen'\n",
    "path_gen = './data/custom_dataset/name_gen'\n",
    "\n",
    "TENSORBOARD_PATH = Path('data/tensorboard/' + proj_id)\n",
    "\n",
    "nf_factor = 1.5\n",
    "pct_start = 1e-8"
   ],
   "id": "4d182f48fba15ed6",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:25:59.488874Z",
     "start_time": "2025-05-21T00:25:59.482101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data(bs:int, sz:int, keep_pct:float):\n",
    "    return get_colorize_data(sz=sz, bs=bs, crappy_path=path_lr, good_path=path_hr,\n",
    "                             random_seed=None, keep_pct=keep_pct)\n",
    "\n",
    "def get_crit_data(classes, bs, sz):\n",
    "    src = ImageList.from_folder(path, include=classes, recurse=True).split_by_rand_pct(0.1, seed=42)\n",
    "    ll = src.label_from_folder(classes=classes)\n",
    "    data = (ll.transform(get_transforms(max_zoom=2.), size=sz)\n",
    "           .databunch(bs=bs).normalize(imagenet_stats))\n",
    "    return data\n",
    "\n",
    "def save_preds(dl):\n",
    "    i=0\n",
    "    names = dl.dataset.items\n",
    "\n",
    "    for b in dl:\n",
    "        preds = learn_gen.pred_batch(batch=b, reconstruct=True)\n",
    "        for o in preds:\n",
    "            o.save(path_gen/names[i].name)\n",
    "            i += 1\n",
    "\n",
    "def save_gen_images():\n",
    "    if path_gen.exists(): shutil.rmtree(path_gen)\n",
    "    path_gen.mkdir(exist_ok=True)\n",
    "    data_gen = get_data(bs=bs, sz=sz, keep_pct=0.085)\n",
    "    save_preds(data_gen.fix_dl)\n",
    "    PIL.Image.open(path_gen.ls()[0])"
   ],
   "id": "6b379e1e27b2508c",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:26:00.385936Z",
     "start_time": "2025-05-21T00:26:00.359162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path  # Also needed\n",
    "\n",
    "# Save Image\n",
    "\n",
    "def save_image(filename, image):\n",
    "    # Extract filename\n",
    "    output_dir = Path(path_lr)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dest = output_dir / filename\n",
    "    image.save(dest, format=\"JPEG\")\n",
    "\n",
    "def save_cv2(filename, image):\n",
    "    output_dir = Path(path_lr)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dest = output_dir / filename\n",
    "    cv2.imwrite(str(dest), image)\n",
    "\n",
    "def save_image_before(filename, image):\n",
    "    # Extract filename\n",
    "    output_dir = Path(path_hr)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dest = output_dir / filename\n",
    "    image.save(dest, format=\"JPEG\")\n",
    "\n",
    "def save_cv2_before(filename, image):\n",
    "    output_dir = Path(path_hr)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dest = output_dir / filename\n",
    "    cv2.imwrite(str(dest), image)\n",
    "\n",
    "# Rotation – Turning the image around a point.\n",
    "\n",
    "\n",
    "def apply_image_rotation(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "\n",
    "\n",
    "    for i in range(90, 271, 90):\n",
    "        # Rotate the image (degrees counter-clockwise)\n",
    "        rotated_image = image.rotate(i, expand=True)  # Use expand=True to resize the output to fit the entire image\n",
    "        filename = f\"{image_name}_rotation_{i}{image_ext}\"\n",
    "        save_image_before(filename, image)\n",
    "        save_image(filename, rotated_image)\n",
    "\n",
    "# Gaussian blur – Smooths the image using a Gaussian function.\n",
    "\n",
    "\n",
    "def apply_gaussian_blur(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    sigmaX_range = np.arange(0.3, 5.1, 0.3)\n",
    "    for sigmaX in sigmaX_range:\n",
    "        blurred = cv2.GaussianBlur(image, (15, 15), sigmaX)\n",
    "        filename = f\"{image_name}_gaussian_blur_{sigmaX:.2f}{image_ext}\"\n",
    "        save_cv2_before(filename, image)\n",
    "        save_cv2(filename, blurred)\n",
    "\n",
    "# Motion blur – Simulates movement during image capture.\n",
    "\n",
    "\n",
    "def apply_motion_blur(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    kernel_sizes = np.arange(5, 46, 1)\n",
    "    angles = np.arange(0, 181, 45)\n",
    "    for kernels in kernel_sizes:\n",
    "        for angle in angles:\n",
    "            # Create the motion_blur blur kernel\n",
    "            kernel = np.zeros((kernels, kernels))\n",
    "            kernel[int((kernels - 1) / 2), :] = np.ones(kernels)\n",
    "\n",
    "            # Rotate the kernel to the desired angle\n",
    "            center = (float(kernels // 2), float(kernels // 2))\n",
    "            rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            kernel = cv2.warpAffine(kernel, rot_mat, (kernels, kernels))\n",
    "\n",
    "            # Normalize the kernel\n",
    "            kernel = kernel / np.sum(kernel)\n",
    "\n",
    "            # Apply the kernel to the image\n",
    "            blurred = cv2.filter2D(image, -1, kernel)\n",
    "            filename = f\"{image_name}_motion_blur_{int(kernels)}{int(angle)}{image_ext}\"\n",
    "            save_cv2_before(filename, image)\n",
    "            save_cv2(filename, blurred)\n",
    "\n",
    "# Defocus blur – Mimics an out-of-focus lens effect.\n",
    "\n",
    "\n",
    "def apply_defocus_blur(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    radii = [i for i in range(3, 21, 1)]\n",
    "    for radius in radii:\n",
    "        kernel_size = radius * 2 + 1\n",
    "        y, x = np.ogrid[:kernel_size, :kernel_size]\n",
    "        center = (radius, radius)\n",
    "        mask = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= radius ** 2\n",
    "        kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)\n",
    "        kernel[mask] = 1\n",
    "        kernel /= np.sum(kernel)\n",
    "\n",
    "        # Apply the kernel using filter2D\n",
    "        blurred = cv2.filter2D(image, -1, kernel)\n",
    "        filename = f\"{image_name}_defocus_blur_{int(radius)}{image_ext}\"\n",
    "        save_cv2_before(filename, image)\n",
    "        save_cv2(filename, blurred)\n",
    "\n",
    "# Radial blur – Blur increases from center outward (like a zoom effect).\n",
    "\n",
    "\n",
    "def apply_radial_blur(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    strengths = [i for i in range(5, 31, 1)]\n",
    "    for strength in strengths:\n",
    "        h, w = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        blurred = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "        # Blend progressively zoomed images\n",
    "        for i in range(1, strength + 1):\n",
    "            zoom_factor = 1 + (i / (strength * 10))\n",
    "            M = cv2.getRotationMatrix2D(center, 0, zoom_factor)\n",
    "            zoomed = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "            alpha = 1.0 / strength\n",
    "            blurred += zoomed.astype(np.float32) * alpha\n",
    "\n",
    "        radial_blur = np.clip(blurred, 0, 255).astype(np.uint8)\n",
    "        filename = f\"{image_name}_radial_blur_{int(strength)}{image_ext}\"\n",
    "        save_cv2_before(filename, image)\n",
    "        save_cv2(filename, radial_blur)\n",
    "\n",
    "# Contrast change – Altering difference between light/dark areas.\n",
    "\n",
    "\n",
    "def apply_adaptive_contrast_clahe(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    clip_limits = [i for i in range(1, 12, 1)]\n",
    "    tile_grid_sizes = [(i, i) for i in range(4, 16, 1)]\n",
    "    for clip_limit in clip_limits:\n",
    "        for tile_grid_size in tile_grid_sizes:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "            enhanced = clahe.apply(gray)\n",
    "            blurred = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)\n",
    "            filename = f\"{image_name}_contrast_clahe_{int(clip_limit)}{int(tile_grid_size[0])}{image_ext}\"\n",
    "            save_cv2_before(filename, image)\n",
    "            save_cv2(filename, blurred)\n",
    "\n",
    "# Color jittering – Random small changes to brightness, contrast, etc.\n",
    "\n",
    "\n",
    "def apply_color_jitter(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    brightness_arr = np.arange(0.1, 1.0, 0.1)\n",
    "    contrast_arr = np.arange(0.1, 1.0, 0.1)\n",
    "    saturation_arr = np.arange(0.1, 1.0, 0.1)\n",
    "    hue_arr = [i for i in range(0, 181, 10)]\n",
    "\n",
    "    for brightness in brightness_arr:\n",
    "        for contrast in contrast_arr:\n",
    "            for saturation in saturation_arr:\n",
    "                for hue in hue_arr:\n",
    "\n",
    "                    if brightness == 0.1 and contrast == 0.2 and saturation == 0.6 and hue == 130: return\n",
    "                    # Randomly adjust brightness\n",
    "                    brightness_factor = random.uniform(1 - brightness, 1 + brightness)\n",
    "                    image = np.clip(image * brightness_factor, 0, 255).astype(np.uint8)\n",
    "\n",
    "                    # Convert to HSV for color adjustments\n",
    "                    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                    # Randomly adjust saturation\n",
    "                    saturation_factor = random.uniform(1 - saturation, 1 + saturation)\n",
    "                    hsv[..., 1] = np.clip(hsv[..., 1] * saturation_factor, 0, 255)\n",
    "\n",
    "                    # Randomly adjust hue\n",
    "                    hue_shift = random.randint(-hue, hue)\n",
    "                    h = hsv[..., 0].astype(int)\n",
    "                    h = (h + hue_shift) % 180\n",
    "                    hsv[..., 0] = h.astype(np.uint8)  # Ensure hue is in [0, 180]\n",
    "\n",
    "                    # Convert back to BGR\n",
    "                    image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "                    # Randomly adjust contrast by scaling pixel values\n",
    "                    contrast_factor = random.uniform(1 - contrast, 1 + contrast)\n",
    "                    new_img = np.clip((image - 128) * contrast_factor + 128, 0, 255).astype(np.uint8)\n",
    "                    filename = f\"{image_name}_color_jitter_{brightness:.2f}{contrast:.2f}{saturation:.2f}{int(hue)}{image_ext}\"\n",
    "                    save_cv2_before(filename, image)\n",
    "                    save_cv2(filename, new_img)\n",
    "\n",
    "# Gaussian noise – Random pixel values with normal distribution.\n",
    "\n",
    "\n",
    "def apply_gaussian_noise(image_path, mean=0):\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    # Open the image and convert it to a numpy array\n",
    "    image = Image.open(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    image_array = np.array(image)\n",
    "    sigmas = [i for i in range(10, 50, 5)]\n",
    "    for sigma in sigmas:\n",
    "        # Generate Gaussian noise\n",
    "        gauss_noise = np.random.normal(mean, sigma, image_array.shape)\n",
    "\n",
    "        # Add the noise to the image array\n",
    "        noisy_image_array = image_array + gauss_noise\n",
    "\n",
    "        # Clip the values to be within valid range (0 to 255)\n",
    "        noisy_image_array = np.clip(noisy_image_array, 0, 255)\n",
    "\n",
    "        # Convert the noisy image array back to an image\n",
    "        noisy_image = Image.fromarray(np.uint8(noisy_image_array))\n",
    "        filename = f\"{image_name}_gaussian_noise_{int(sigma)}{image_ext}\"\n",
    "        save_image_before(filename, image)\n",
    "        save_image(filename, noisy_image)\n",
    "\n",
    "# Salt & pepper noise – Random black and white pixels.\n",
    "\n",
    "\n",
    "def apply_salt_and_pepper_noise(image_path):\n",
    "    # Open the image and convert it to a numpy array\n",
    "    image = Image.open(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    salt = np.arange(0.01, 0.1, 0.01)\n",
    "    pepper = np.arange(0.01, 0.1, 0.01)\n",
    "    for salt_prob in salt:\n",
    "        for pepper_prob in pepper:\n",
    "            # Generate random salt-and-pepper noise\n",
    "            noisy_image_array = image_array.copy()\n",
    "\n",
    "            if noisy_image_array.ndim != 3: continue\n",
    "            # Add salt (white pixels)\n",
    "            num_salt = int(salt_prob * image_array.size)\n",
    "            salt_coords = [np.random.randint(0, i, num_salt) for i in image_array.shape[:2]]\n",
    "            noisy_image_array[salt_coords[0], salt_coords[1], :] = 255\n",
    "\n",
    "            # Add pepper (black pixels)\n",
    "            num_pepper = int(pepper_prob * image_array.size)\n",
    "            pepper_coords = [np.random.randint(0, i, num_pepper) for i in image_array.shape[:2]]\n",
    "            noisy_image_array[pepper_coords[0], pepper_coords[1], :] = 0\n",
    "\n",
    "            # Convert the noisy image array back to an image\n",
    "            noisy_image = Image.fromarray(np.uint8(noisy_image_array))\n",
    "            filename = f\"{image_name}_salt_pepper_{salt_prob:.2f}{pepper_prob:.2f}{image_ext}\"\n",
    "            save_image_before(filename, image)\n",
    "            save_image(filename, noisy_image)\n",
    "\n",
    "# Speckle noise – Multiplicative noise, often in radar/medical images.\n",
    "\n",
    "\n",
    "def apply_speckle_noise(image_path):\n",
    "    sigmas = np.arange(0.05, 0.51, 0.05)\n",
    "\n",
    "    # Open the image and convert it to a numpy array\n",
    "    image = Image.open(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        # Generate speckle noise (multiplicative noise)\n",
    "        noise = np.random.normal(0, sigma, image_array.shape)\n",
    "\n",
    "        # Add speckle noise to the image\n",
    "        noisy_image_array = image_array + image_array * noise\n",
    "\n",
    "        # Clip the values to be within valid range (0 to 255)\n",
    "        noisy_image_array = np.clip(noisy_image_array, 0, 255)\n",
    "\n",
    "        # Convert the noisy image array back to an image\n",
    "        noisy_image = Image.fromarray(np.uint8(noisy_image_array))\n",
    "        filename = f\"{image_name}_speckle_noise_{sigma:.2f}{image_ext}\"\n",
    "        save_image_before(filename, image)\n",
    "        save_image(filename, noisy_image)\n",
    "\n",
    "# Banding artifacts – Horizontal or vertical lines due to poor encoding.\n",
    "\n",
    "\n",
    "def apply_banding_artifacts(image_path):\n",
    "    colors = [2, 16, 64]\n",
    "    image = Image.open(image_path)\n",
    "    image_name = Path(image_path).stem\n",
    "    image_ext = \".jpeg\"\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Normalize the image to the range [0, 1]\n",
    "    image_array = image_array / 255.0\n",
    "\n",
    "    for num_colors in colors:\n",
    "        # Quantize each color channel to a limited number of levels\n",
    "        quantized_image_array = np.floor(image_array * num_colors) / num_colors\n",
    "\n",
    "        # Convert the image array back to the range [0, 255]\n",
    "        quantized_image_array = (quantized_image_array * 255).astype(np.uint8)\n",
    "\n",
    "        # Convert the noisy image array back to an image\n",
    "        noisy_image = Image.fromarray(quantized_image_array)\n",
    "        filename = f\"{image_name}_artifacts_{int(num_colors)}{image_ext}\"\n",
    "        save_image_before(filename, image)\n",
    "        save_image(filename, noisy_image)\n",
    "\n",
    "# Occlusion – Random parts of image covered (e.g., with boxes).\n",
    "\n",
    "\n",
    "def apply_random_occlusion_boxes(image_path):\n",
    "    for i in range(10):\n",
    "        # Create a drawing object to draw on the image\n",
    "        before_image = Image.open(image_path)\n",
    "        after_image = before_image.copy()\n",
    "        image_name = Path(image_path).stem\n",
    "        image_ext = \".jpeg\"\n",
    "        draw = ImageDraw.Draw(after_image)\n",
    "\n",
    "        # Get image dimensions\n",
    "        width, height = after_image.size\n",
    "\n",
    "        for j in range(10):\n",
    "            # Randomly select the size of the box within the maximum size\n",
    "            box_width = np.random.randint(int(width * 0.125), int(width * 0.3))\n",
    "            box_height = np.random.randint(int(width * 0.125), int(width * 0.3))\n",
    "\n",
    "            # Randomly select top-left corner for the box (ensuring it fits within the image)\n",
    "            top_left_x = np.random.randint(0, width - box_width)\n",
    "            top_left_y = np.random.randint(0, height - box_height)\n",
    "\n",
    "            # Define the box coordinates (top-left and bottom-right corners)\n",
    "            bottom_right_x = top_left_x + box_width\n",
    "            bottom_right_y = top_left_y + box_height\n",
    "\n",
    "            # Draw a black box (occlusion)\n",
    "            draw.rectangle([top_left_x, top_left_y, bottom_right_x, bottom_right_y], fill=\"black\")\n",
    "            filename = f\"{image_name}_boxes_{int(i)}{int(j)}{image_ext}\"\n",
    "            save_image_before(filename, before_image)\n",
    "            save_image(filename, after_image)\n",
    "\n",
    "\n",
    "def create_training_images(fn,i):\n",
    "    apply_image_rotation(fn)\n",
    "    apply_gaussian_blur(fn)\n",
    "    apply_adaptive_contrast_clahe(fn)\n",
    "    apply_color_jitter(fn)\n",
    "    apply_gaussian_noise(fn)\n",
    "    apply_salt_and_pepper_noise(fn)\n",
    "    apply_speckle_noise(fn)\n",
    "    apply_banding_artifacts(fn)\n",
    "    apply_random_occlusion_boxes(fn)\n"
   ],
   "id": "b08a26d798aed0b8",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:26:05.139119Z",
     "start_time": "2025-05-21T00:26:02.432098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "il = full_train[:10] #100000 train, 240000 total\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(create_training_images, str(fn), i) for i, fn in enumerate(il)]\n",
    "    for f in futures:\n",
    "        f.result()"
   ],
   "id": "38a15c5d7f8613cd",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:26:05.171489Z",
     "start_time": "2025-05-21T00:26:05.142474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "path_hr = './data/custom_dataset/norm/sample_train/'\n",
    "files = os.listdir(path_hr)\n",
    "files2 = os.listdir(path_lr)\n",
    "print(len(files))\n",
    "print(len(files2))"
   ],
   "id": "296ca2fd0840514e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300\n",
      "6300\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T00:53:41.212359Z",
     "start_time": "2025-05-21T00:26:50.621772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bs=88\n",
    "sz=64\n",
    "keep_pct=1.0\n",
    "data_gen = get_data(bs=bs, sz=sz, keep_pct=keep_pct)\n",
    "learn_gen = gen_learner_deep(data=data_gen, gen_loss=FeatureLoss(), nf_factor=nf_factor)\n",
    "learn_gen.load(pretrained_gen_path, with_opt=False)\n",
    "learn_gen.callback_fns.append(partial(ImageGenTensorboardWriter, base_dir=TENSORBOARD_PATH, name='GenPre'))\n",
    "learn_gen.fit_one_cycle(1, pct_start=0.8, max_lr=slice(1e-3))\n",
    "learn_gen.save(pre_gen_name)\n",
    "learn_gen.unfreeze()\n",
    "learn_gen.fit_one_cycle(1, pct_start=pct_start,  max_lr=slice(3e-7, 3e-4))\n",
    "learn_gen.save(pre_gen_name)\n"
   ],
   "id": "c0d577fec0b7ce01",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xndc4\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xndc4\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xndc4\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xndc4\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\xndc4\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\xndc4\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\xndc4\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "C:\\Users\\xndc4\\PycharmProjects\\masters_project\\DeOldify\\fastai\\basic_train.py:322: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(tmp_file)\n",
      "C:\\Users\\xndc4\\PycharmProjects\\masters_project\\DeOldify\\fastai\\basic_train.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(source, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.262414</td>\n",
       "      <td>5.705962</td>\n",
       "      <td>12:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary name /metrics/train_loss is illegal; using metrics/train_loss instead.\n",
      "Summary name /metrics/train_loss is illegal; using metrics/train_loss instead.\n",
      "Summary name /metrics/valid_loss is illegal; using metrics/valid_loss instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.394530</td>\n",
       "      <td>5.327067</td>\n",
       "      <td>12:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary name /metrics/train_loss is illegal; using metrics/train_loss instead.\n",
      "Summary name /metrics/train_loss is illegal; using metrics/train_loss instead.\n",
      "Summary name /metrics/valid_loss is illegal; using metrics/valid_loss instead.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "93b1f54b4dd43431",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
